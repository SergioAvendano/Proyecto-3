# -*- coding: utf-8 -*-
"""K2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e-Sf-eF282NzGh0S_KimdmgV7oTNOODE
"""

pip install pgmpy networkx matplotlib

import pandas as pd
from pgmpy.models import BayesianModel
import networkx as nx
import matplotlib.pyplot as plt

# Leer datos
df = pd.read_excel("/content/drive/MyDrive/Colab Notebooks/DatosP3Final.xlsx")

# Limpiar datos
#df = df.dropna()

print(df.head())
print(df.describe())
print(df.columns)

from pgmpy.models import BayesianModel

from pgmpy.estimators import HillClimbSearch
from pgmpy.estimators import K2Score
from pgmpy.models import BayesianNetwork

scoring_method = K2Score(data=df)
esth = HillClimbSearch(data=df)
estimated_modelh = esth.estimate(
    scoring_method=scoring_method, max_indegree=100000, max_iter=int(1e4)
)
print(estimated_modelh)
print(estimated_modelh.nodes())
print(estimated_modelh.edges())


estimated_modelh = BayesianNetwork(estimated_modelh)

print(scoring_method.score(estimated_modelh))


nx.draw_shell(estimated_modelh, with_labels=True)

from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator

estimated_modelh.fit(data=df, estimator = MaximumLikelihoodEstimator)
for i in estimated_modelh.nodes():
    print(estimated_modelh.get_cpds(i))

from pgmpy.inference import VariableElimination
from sklearn.metrics import accuracy_score, confusion_matrix

import pandas as pd
from pgmpy.estimators import HillClimbSearch, K2Score
from pgmpy.models import BayesianNetwork
from pgmpy.inference import VariableElimination
from sklearn.metrics import accuracy_score

inference = VariableElimination(estimated_modelh)
estimated_modelh = BayesianNetwork(estimated_modelh)

# Definir las variables que estás usando en tu modelo
variables = ['periodo', 'cole_depto_ubicacion', 'fami_tieneinternet', 'cole_jornada', 'cole_bilingue', 'fami_estratovivienda', 'punt_global']


# Definir las variables observadas y no observadas
observed_variables = ['periodo', 'cole_depto_ubicacion', 'fami_tieneinternet', 'cole_jornada', 'cole_bilingue', 'fami_estratovivienda']
target_variable = 'punt_global'


# Convertir las columnas a un diccionario
evidence_dict = df[observed_variables].to_dict(orient='records')[0]

# Convertir a BayesianNetwork
bayesian_model = BayesianNetwork(estimated_modelh)

predicted_values = inference.map_query(variables=[target_variable], evidence=df[observed_variables].iloc[0].to_dict())

# Obtener las etiquetas reales
true_values = df[target_variable]

# Convertir a listas
true_values_list = list(true_values)

# Manejar el caso en el que el valor predicho es una cadena o un número
predicted_value = predicted_values[target_variable]
if isinstance(predicted_value, str):
    predicted_values_list = [predicted_value]
else:
    predicted_values_list = [predicted_value.item()]


# Calcular la precisión
accuracy = accuracy_score(true_values_list, [predicted_values_list[0] for _ in range(len(true_values_list))])
print(f'Accuracy: {accuracy:.4f}')

from sklearn.model_selection import train_test_split
from pgmpy.models import BayesianNetwork
train,test = train_test_split(df, test_size=0.2,random_state= 42)

train

from pgmpy.estimators import HillClimbSearch
from pgmpy.estimators import K2Score
from pgmpy.models import BayesianNetwork

scoring_method = K2Score(data=train)
esth = HillClimbSearch(data=train)
estimated_modelhT = esth.estimate(
    scoring_method=scoring_method, max_indegree=100000, max_iter=int(1e4)
)
print(estimated_modelhT)
print(estimated_modelhT.nodes())
print(estimated_modelhT.edges())


estimated_modelhT = BayesianNetwork(estimated_modelhT)

print(scoring_method.score(estimated_modelhT))


nx.draw_shell(estimated_modelhT, with_labels=True)

from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator

estimated_modelhT.fit(data=train, estimator = MaximumLikelihoodEstimator)
for i in estimated_modelhT.nodes():
    print(estimated_modelhT.get_cpds(i))

inferenceT = VariableElimination(estimated_modelhT)
estimated_modelhT = BayesianNetwork(estimated_modelhT)

# Obtener las predicciones de Target
predicted_target = []
for idx, row in df.iterrows():
    evidence = {
        "periodo": row["periodo"],
        "fami_tieneinternet": row["fami_tieneinternet"],
        "cole_jornada": row["cole_jornada"],
        "cole_bilingue": row["cole_bilingue"],
        "fami_estratovivienda": row["fami_estratovivienda"]
    }
    target_probabilities = inference.query(variables=["punt_global"], evidence=evidence)
    predicted_target.append(target_probabilities.values.argmax())

# Calcular la precisión
actual_target = df["punt_global"].tolist()
accuracy = accuracy_score(actual_target, predicted_target)
print(f"Precisión (Accuracy): {accuracy:.2f}")

from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator

estimated_modelhT.fit(data=train, estimator = MaximumLikelihoodEstimator)
for i in estimated_modelhT.nodes():
    print(estimated_modelhT.get_cpds(i))

inferenceT = VariableElimination(estimated_modelhT)
estimated_modelhT = BayesianNetwork(estimated_modelhT)

# Definir las variables que estás usando en tu modelo
variables = ['periodo', 'cole_depto_ubicacion', 'fami_tieneinternet', 'cole_jornada', 'cole_bilingue', 'fami_estratovivienda', 'punt_global']


# Definir las variables observadas y no observadas
observed_variables = ['periodo', 'cole_depto_ubicacion', 'fami_tieneinternet', 'cole_jornada', 'cole_bilingue', 'fami_estratovivienda']
target_variable = 'punt_global'


# Convertir las columnas a un diccionario
evidence_dict = train[observed_variables].to_dict(orient='records')[0]

# Convertir a BayesianNetwork
bayesian_model = BayesianNetwork(estimated_modelhT)

predicted_values = inferenceT.map_query(variables=[target_variable], evidence=train[observed_variables].iloc[0].to_dict())

# Obtener las etiquetas reales
true_values = train[target_variable]

# Convertir a listas
true_values_list = list(true_values)
predicted_values_list = [predicted_values[target_variable].item()]  # Convertir el valor predicho a un tipo de datos nativo

# Calcular la precisión
accuracy = accuracy_score(true_values_list, [predicted_values_list[0] for _ in range(len(true_values_list))])
print(f'Accuracy: {accuracy:.4f}')

from numpy.matrixlib.defmatrix import mat
matriz = confusion_matrix(df["punt_global"],predicted_target)

matriz

import pickle

# Ruta completa o relativa al directorio donde deseas guardar el archivo de pickle
filename = r"/home/ubuntu/resultados.pkl"

with open(filename,'wb') as file:
    pickle.dump(estimated_modelhT , file)
    file.close()